{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gR2TTKtjyOQY",
        "outputId": "8ac2aabe-d991-4561-a9c7-d5c1a64d5342"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import pandas as pd\n",
        "from torchvision.io import decode_image\n",
        "from datasets import load_dataset\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from torchvision import transforms, datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define Constants"
      ],
      "metadata": {
        "id": "lwRXNDTPqcs1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "7CQoSd-F8I9m"
      },
      "outputs": [],
      "source": [
        "labels_map = {\n",
        "    0: \"Anthracnose\",\n",
        "    1: \"Banana Fruit-Scarring Beetle\",\n",
        "    2: \"Banana Skipper Damage\",\n",
        "    3: 'Banana Split Peel',\n",
        "    4: \"Black and Yellow Sigatoka\",\n",
        "    5: \"Chewing insect damage on banana leaf\",\n",
        "    6: \"Healthy Banana\",\n",
        "    7: \"Healthy Banana leaf\",\n",
        "    8: \"Panama Wilt Disease\",\n",
        "}\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define HyperParameters"
      ],
      "metadata": {
        "id": "EwX0QsxQYdme"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 9\n",
        "# hyperparams\n",
        "num_epochs = 1\n",
        "batch_size = 64\n",
        "learning_rate = 0.01\n",
        "decay = 0.001\n",
        "moment = 0.9"
      ],
      "metadata": {
        "id": "ArasSRm4YcOl"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import image dataset from drive"
      ],
      "metadata": {
        "id": "lCpfpxyEqjUu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "dataset_path = '/content/drive/MyDrive/bananadata/AUGMENTED/data'\n",
        "build_path = '/content/drive/MyDrive/bananadata/build/augs'\n"
      ],
      "metadata": {
        "id": "to92Nzof6xwe"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define Image transformations to fit model"
      ],
      "metadata": {
        "id": "zjOaHFgpqr33"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "pKJANUvNswoG"
      },
      "outputs": [],
      "source": [
        "normalize = transforms.Normalize(\n",
        "        mean=[0.5, 0.5, 0.5],\n",
        "        std=[0.5, 0.5, 0.5],\n",
        "    )\n",
        "transform = transforms.Compose([\n",
        "            transforms.Resize((224,224)),\n",
        "            transforms.ToTensor(),\n",
        "            normalize\n",
        "    ])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get images from drive and apply Transfomation to image datasets"
      ],
      "metadata": {
        "id": "wo5RC-Rnq08S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_train = datasets.ImageFolder(root=dataset_path+'/train', transform=transform)\n",
        "dataset_val = datasets.ImageFolder(root=dataset_path+'/validation', transform=transform)\n",
        "dataset_test = datasets.ImageFolder(root=dataset_path+'/test', transform=transform)\n",
        "build_train = datasets.ImageFolder(root=build_path, transform=transform)"
      ],
      "metadata": {
        "id": "L73FGE7r6_iT"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "load images to DataLoader"
      ],
      "metadata": {
        "id": "dMgd4U72q7Fp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "6uLfDx_6NgDO"
      },
      "outputs": [],
      "source": [
        "\n",
        "load_train = DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
        "load_val = DataLoader(dataset_val, batch_size=batch_size, shuffle=True)\n",
        "load_test = DataLoader(dataset_test, batch_size=batch_size, shuffle=True)\n",
        "load_build = DataLoader(build_train, batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9DE6nRfSRbin",
        "outputId": "4b41e22f-68b7-4097-e54b-870e065213db"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset ImageFolder\n",
              "    Number of datapoints: 7605\n",
              "    Root location: /content/drive/MyDrive/bananadata/AUGMENTED/data/train\n",
              "    StandardTransform\n",
              "Transform: Compose(\n",
              "               Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=True)\n",
              "               ToTensor()\n",
              "               Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
              "           )"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "load_train.dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for images, labels in load_val:\n",
        "    print(images.shape)\n",
        "    print(labels.shape)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j3qpINewJZZn",
        "outputId": "29189870-9d5a-4c64-dd51-2a041a5a4203"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 3, 224, 224])\n",
            "torch.Size([64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define VGG16 architecture CNN model"
      ],
      "metadata": {
        "id": "XhjK7vE6rEHJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "vJp0-6Ie-Jgs"
      },
      "outputs": [],
      "source": [
        "class VGG16(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(VGG16, self).__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU())\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
        "        self.layer3 = nn.Sequential(\n",
        "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU())\n",
        "        self.layer4 = nn.Sequential(\n",
        "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
        "        self.layer5 = nn.Sequential(\n",
        "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU())\n",
        "        self.layer6 = nn.Sequential(\n",
        "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU())\n",
        "        self.layer7 = nn.Sequential(\n",
        "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
        "        self.layer8 = nn.Sequential(\n",
        "            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU())\n",
        "        self.layer9 = nn.Sequential(\n",
        "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU())\n",
        "        self.layer10 = nn.Sequential(\n",
        "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
        "        self.layer11 = nn.Sequential(\n",
        "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU())\n",
        "        self.layer12 = nn.Sequential(\n",
        "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU())\n",
        "        self.layer13 = nn.Sequential(\n",
        "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(7*7*512, 4096),\n",
        "            nn.ReLU())\n",
        "        self.fc1 = nn.Sequential(\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU())\n",
        "        self.fc2= nn.Sequential(\n",
        "            nn.Linear(4096, num_classes))\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = self.layer5(out)\n",
        "        out = self.layer6(out)\n",
        "        out = self.layer7(out)\n",
        "        out = self.layer8(out)\n",
        "        out = self.layer9(out)\n",
        "        out = self.layer10(out)\n",
        "        out = self.layer11(out)\n",
        "        out = self.layer12(out)\n",
        "        out = self.layer13(out)\n",
        "        out = out.reshape(out.size(0), -1)\n",
        "        out = self.fc(out)\n",
        "        out = self.fc1(out)\n",
        "        out = self.fc2(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define model"
      ],
      "metadata": {
        "id": "xdLk0odBrLrD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "zEgL1CxQp4gi"
      },
      "outputs": [],
      "source": [
        "model = VGG16(num_classes).to(device)\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "train_accuracies = []\n",
        "val_accuracies = []\n",
        "\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay = decay, momentum = moment)\n",
        "\n",
        "\n",
        "# Train the model\n",
        "total_step = len(load_train)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training"
      ],
      "metadata": {
        "id": "UVIUqKt1rRSE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qqj56EctqKZx"
      },
      "outputs": [],
      "source": [
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    for i, batch in enumerate(load_train):\n",
        "        # Move tensors to the configured device\n",
        "        images = batch[0].to(device)\n",
        "        labels = batch[1].to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item() * labels.size(0)\n",
        "    train_loss = running_loss / len(load_train.dataset)\n",
        "    train_losses.append(train_loss)\n",
        "\n",
        "    print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
        "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
        "\n",
        "    # Validation\n",
        "    running_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for images, labels in load_val:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            del images, labels, outputs\n",
        "            running_loss += loss.item() * labels.size(0)\n",
        "        val_loss = running_loss / len(load_val.dataset)\n",
        "        val_losses.append(val_loss)\n",
        "        val_acc = 100 * correct / total\n",
        "        val_accuracies.append(val_acc)\n",
        "        print('Accuracy of the network on the {} validation images: {} %'.format(945, 100 * correct / total))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PLOTS"
      ],
      "metadata": {
        "id": "9ED24U9rrW5T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "20C36Z3p_cuc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "loss plots"
      ],
      "metadata": {
        "id": "ID0odvh5rm_G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(train_losses, label='Training Loss')\n",
        "plt.plot(val_losses, label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "VPcPP_C4AK7J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model.eval()\n",
        "test_y_true = []\n",
        "test_y_pred = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for batch in load_test:\n",
        "        images = batch['image'].to(device)\n",
        "        labels = batch['label'].to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "        y_true.extend(labels.cpu().numpy())\n",
        "        y_pred.extend(predicted.cpu().numpy())\n",
        "\n",
        "        del images, labels, outputs\n"
      ],
      "metadata": {
        "id": "6RtIJ2AynKXu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Accuracy of the network on the {} test images: {} %'.format(len(test_ds), 100 * correct / total))\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "# Plot Confusion Matrix\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels_map.values(), yticklabels=labels_map.values())\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2SaRJF5G_3Lr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "load build dataset here also augment it equally\n",
        "\n",
        "maybe save augmented image dataset for easy repeatability"
      ],
      "metadata": {
        "id": "5fp0KHdJBAci"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_TJuJq36qVUD"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "build_y_true = []\n",
        "build_y_pred = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    # change to buuild dataset\n",
        "    for images, labels in load_build:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        del images, labels, outputs\n",
        "\n",
        "    print('Accuracy of the network on the {} test images: {} %'.format(10000, 100 * correct / total))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: save hyperparameters and results from the learning rate, epoch, batch size, losses and accuracies, test_y_pred and test_y_true, build_y_true and build_y_pred\n",
        "\n",
        "import json\n",
        "import os\n",
        "\n",
        "# Define the directory to save the results\n",
        "results_dir = \"/content/drive/MyDrive/bananadata/results/cnn\"\n",
        "os.makedirs(results_dir, exist_ok=True)\n",
        "\n",
        "# Define hyperparameters and results\n",
        "hyperparameters = {\n",
        "    \"learning_rate\": learning_rate,\n",
        "    \"epoch\": num_epochs,\n",
        "    \"batch_size\": batch_size,\n",
        "    \"optimizer\": \"SGD\",\n",
        "    \"loss_function\": \"CrossEntropyLoss\",\n",
        "    \"model_architecture\": \"VGG16\"\n",
        "}\n",
        "\n",
        "results = {\n",
        "    \"train_losses\": train_losses,\n",
        "    \"val_losses\": val_losses,\n",
        "    # Assuming you calculated training and validation accuracies and stored them in train_accuracies and val_accuracies lists\n",
        "    \"val_accuracies\": val_accuracies,\n",
        "    \"test_y_true\": test_y_true,\n",
        "    \"test_y_pred\": test_y_pred,\n",
        "    \"build_y_true\": build_y_true,\n",
        "    \"build_y_pred\": build_y_pred,\n",
        "}\n",
        "\n",
        "test_index = 1\n",
        "# Save hyperparameters\n",
        "hyperparameters_path = os.path.join(results_dir, f\"hyperparameters{test_index}.json\")\n",
        "with open(hyperparameters_path, \"w\") as f:\n",
        "    json.dump(hyperparameters, f, indent=4)\n",
        "print(f\"Hyperparameters saved to {hyperparameters_path}\")\n",
        "\n",
        "# Save results\n",
        "results_path = os.path.join(results_dir, f\"results{test_index}.json\")\n",
        "with open(results_path, \"w\") as f:\n",
        "    json.dump(results, f)\n",
        "print(f\"Results saved to {results_path}\")"
      ],
      "metadata": {
        "id": "aDLoW77o9Lwf"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}