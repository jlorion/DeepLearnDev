{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gR2TTKtjyOQY",
    "outputId": "8ac2aabe-d991-4561-a9c7-d5c1a64d5342"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "import pandas as pd\n",
    "from torchvision.io import decode_image\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchvision import transforms, datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lwRXNDTPqcs1"
   },
   "source": [
    "Define Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "7CQoSd-F8I9m"
   },
   "outputs": [],
   "source": [
    "labels_map = {\n",
    "    0: \"Anthracnose\",\n",
    "    1: \"Banana Fruit-Scarring Beetle\",\n",
    "    2: \"Banana Skipper Damage\",\n",
    "    3: 'Banana Split Peel',\n",
    "    4: \"Black and Yellow Sigatoka\",\n",
    "    5: \"Chewing insect damage on banana leaf\",\n",
    "    6: \"Healthy Banana\",\n",
    "    7: \"Healthy Banana leaf\",\n",
    "    8: \"Panama Wilt Disease\",\n",
    "}\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EwX0QsxQYdme"
   },
   "source": [
    "Define HyperParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ArasSRm4YcOl"
   },
   "outputs": [],
   "source": [
    "num_classes = 9\n",
    "# hyperparams\n",
    "num_epochs = 1\n",
    "batch_size = 64\n",
    "learning_rate = 0.01\n",
    "decay = 0.001\n",
    "moment = 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lCpfpxyEqjUu"
   },
   "source": [
    "Import image dataset from drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "to92Nzof6xwe"
   },
   "outputs": [],
   "source": [
    "\n",
    "dataset_path = '/content/drive/MyDrive/bananadata/AUGMENTED/data'\n",
    "build_path = '/content/drive/MyDrive/bananadata/build/augs'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zjOaHFgpqr33"
   },
   "source": [
    "Define Image transformations to fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "pKJANUvNswoG"
   },
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(\n",
    "        mean=[0.5, 0.5, 0.5],\n",
    "        std=[0.5, 0.5, 0.5],\n",
    "    )\n",
    "transform = transforms.Compose([\n",
    "            transforms.Resize((224,224)),\n",
    "            transforms.ToTensor(),\n",
    "            normalize\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wo5RC-Rnq08S"
   },
   "source": [
    "Get images from drive and apply Transfomation to image datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "L73FGE7r6_iT"
   },
   "outputs": [],
   "source": [
    "dataset_train = datasets.ImageFolder(root=dataset_path+'/train', transform=transform)\n",
    "dataset_val = datasets.ImageFolder(root=dataset_path+'/validation', transform=transform)\n",
    "dataset_test = datasets.ImageFolder(root=dataset_path+'/test', transform=transform)\n",
    "build_train = datasets.ImageFolder(root=build_path, transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dMgd4U72q7Fp"
   },
   "source": [
    "load images to DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "6uLfDx_6NgDO"
   },
   "outputs": [],
   "source": [
    "\n",
    "load_train = DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
    "load_val = DataLoader(dataset_val, batch_size=batch_size, shuffle=True)\n",
    "load_test = DataLoader(dataset_test, batch_size=batch_size, shuffle=True)\n",
    "load_build = DataLoader(build_train, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9DE6nRfSRbin",
    "outputId": "4b41e22f-68b7-4097-e54b-870e065213db"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset ImageFolder\n",
       "    Number of datapoints: 7605\n",
       "    Root location: /content/drive/MyDrive/bananadata/AUGMENTED/data/train\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=True)\n",
       "               ToTensor()\n",
       "               Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
       "           )"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_train.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j3qpINewJZZn",
    "outputId": "29189870-9d5a-4c64-dd51-2a041a5a4203"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "for images, labels in load_val:\n",
    "    print(images.shape)\n",
    "    print(labels.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XhjK7vE6rEHJ"
   },
   "source": [
    "Define VGG16 architecture CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "vJp0-6Ie-Jgs"
   },
   "outputs": [],
   "source": [
    "class VGG16(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(VGG16, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU())\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU())\n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        self.layer5 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU())\n",
    "        self.layer6 = nn.Sequential(\n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU())\n",
    "        self.layer7 = nn.Sequential(\n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        self.layer8 = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU())\n",
    "        self.layer9 = nn.Sequential(\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU())\n",
    "        self.layer10 = nn.Sequential(\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        self.layer11 = nn.Sequential(\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU())\n",
    "        self.layer12 = nn.Sequential(\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU())\n",
    "        self.layer13 = nn.Sequential(\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(7*7*512, 4096),\n",
    "            nn.ReLU())\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU())\n",
    "        self.fc2= nn.Sequential(\n",
    "            nn.Linear(4096, num_classes))\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.layer5(out)\n",
    "        out = self.layer6(out)\n",
    "        out = self.layer7(out)\n",
    "        out = self.layer8(out)\n",
    "        out = self.layer9(out)\n",
    "        out = self.layer10(out)\n",
    "        out = self.layer11(out)\n",
    "        out = self.layer12(out)\n",
    "        out = self.layer13(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xdLk0odBrLrD"
   },
   "source": [
    "Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "zEgL1CxQp4gi"
   },
   "outputs": [],
   "source": [
    "model = VGG16(num_classes).to(device)\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay = decay, momentum = moment)\n",
    "\n",
    "\n",
    "# Train the model\n",
    "total_step = len(load_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UVIUqKt1rRSE"
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qqj56EctqKZx"
   },
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, batch in enumerate(load_train):\n",
    "        # Move tensors to the configured device\n",
    "        images = batch[0].to(device)\n",
    "        labels = batch[1].to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * labels.size(0)\n",
    "    train_loss = running_loss / len(load_train.dataset)\n",
    "    train_losses.append(train_loss)\n",
    "\n",
    "    print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
    "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
    "\n",
    "    # Validation\n",
    "    running_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in load_val:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            del images, labels, outputs\n",
    "            running_loss += loss.item() * labels.size(0)\n",
    "        val_loss = running_loss / len(load_val.dataset)\n",
    "        val_losses.append(val_loss)\n",
    "        val_acc = 100 * correct / total\n",
    "        val_accuracies.append(val_acc)\n",
    "        print('Accuracy of the network on the {} validation images: {} %'.format(945, 100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9ED24U9rrW5T"
   },
   "source": [
    "## PLOTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "20C36Z3p_cuc"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ID0odvh5rm_G"
   },
   "source": [
    "loss plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VPcPP_C4AK7J"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6RtIJ2AynKXu"
   },
   "outputs": [],
   "source": [
    "\n",
    "model.eval()\n",
    "test_y_true = []\n",
    "test_y_pred = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch in load_test:\n",
    "        images = batch['image'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        y_pred.extend(predicted.cpu().numpy())\n",
    "\n",
    "        del images, labels, outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2SaRJF5G_3Lr"
   },
   "outputs": [],
   "source": [
    "print('Accuracy of the network on the {} test images: {} %'.format(len(test_ds), 100 * correct / total))\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Plot Confusion Matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels_map.values(), yticklabels=labels_map.values())\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5fp0KHdJBAci"
   },
   "source": [
    "load build dataset here also augment it equally\n",
    "\n",
    "maybe save augmented image dataset for easy repeatability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_TJuJq36qVUD"
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "build_y_true = []\n",
    "build_y_pred = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    # change to buuild dataset\n",
    "    for images, labels in load_build:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        del images, labels, outputs\n",
    "\n",
    "    print('Accuracy of the network on the {} test images: {} %'.format(10000, 100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aDLoW77o9Lwf"
   },
   "outputs": [],
   "source": [
    "# prompt: save hyperparameters and results from the learning rate, epoch, batch size, losses and accuracies, test_y_pred and test_y_true, build_y_true and build_y_pred\n",
    "\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Define the directory to save the results\n",
    "results_dir = \"/content/drive/MyDrive/bananadata/results/cnn\"\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "# Define hyperparameters and results\n",
    "hyperparameters = {\n",
    "    \"learning_rate\": learning_rate,\n",
    "    \"epoch\": num_epochs,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"optimizer\": \"SGD\",\n",
    "    \"loss_function\": \"CrossEntropyLoss\",\n",
    "    \"model_architecture\": \"VGG16\"\n",
    "}\n",
    "\n",
    "results = {\n",
    "    \"train_losses\": train_losses,\n",
    "    \"val_losses\": val_losses,\n",
    "    # Assuming you calculated training and validation accuracies and stored them in train_accuracies and val_accuracies lists\n",
    "    \"val_accuracies\": val_accuracies,\n",
    "    \"test_y_true\": test_y_true,\n",
    "    \"test_y_pred\": test_y_pred,\n",
    "    \"build_y_true\": build_y_true,\n",
    "    \"build_y_pred\": build_y_pred,\n",
    "}\n",
    "\n",
    "test_index = 1\n",
    "# Save hyperparameters\n",
    "hyperparameters_path = os.path.join(results_dir, f\"hyperparameters{test_index}.json\")\n",
    "with open(hyperparameters_path, \"w\") as f:\n",
    "    json.dump(hyperparameters, f, indent=4)\n",
    "print(f\"Hyperparameters saved to {hyperparameters_path}\")\n",
    "\n",
    "# Save results\n",
    "results_path = os.path.join(results_dir, f\"results{test_index}.json\")\n",
    "with open(results_path, \"w\") as f:\n",
    "    json.dump(results, f)\n",
    "print(f\"Results saved to {results_path}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V28",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
